#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•Graph Transformeræ¨¡å‹
"""
import sys
import os
import numpy as np
import torch
import warnings
warnings.filterwarnings("ignore")

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from params import params
from dataset import load_data, split_time_series_data, StockDataset
from model import create_model
from torch.utils.data import DataLoader

def test_graph_transformer():
    """æµ‹è¯•Graph Transformeræ¨¡å‹"""
    print("=" * 60)
    print("æµ‹è¯•Graph Transformeræ¨¡å‹")
    print("=" * 60)
    
    try:
        # å¯ç”¨æµ‹è¯•æ¨¡å¼
        params.test_mode = True
        
        # åŠ è½½æ•°æ®
        print("1. åŠ è½½æ•°æ®...")
        X, y, time_stamps = load_data()
        (X_train, X_val, X_test), (y_train, y_val, y_test), (ts_train, ts_val, ts_test) = split_time_series_data(X, y, time_stamps)
        
        print(f"   è®­ç»ƒé›†: X={X_train.shape}, y={y_train.shape}")
        print(f"   éªŒè¯é›†: X={X_val.shape}, y={y_val.shape}")
        print(f"   æµ‹è¯•é›†: X={X_test.shape}, y={y_test.shape}")
        
        # åˆ›å»ºæ•°æ®é›†
        print("2. åˆ›å»ºæ•°æ®é›†...")
        train_dataset = StockDataset(X_train, y_train)
        val_dataset = StockDataset(X_val, y_val)
        
        train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
        
        print(f"   è®­ç»ƒæ‰¹æ¬¡æ•°é‡: {len(train_loader)}")
        print(f"   éªŒè¯æ‰¹æ¬¡æ•°é‡: {len(val_loader)}")
        
        # åˆ›å»ºæ¨¡å‹
        print("3. åˆ›å»ºæ¨¡å‹...")
        model = create_model(params)
        
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model = model.to(device)
        
        print(f"   æ¨¡å‹ç±»å‹: {type(model).__name__}")
        print(f"   è®¾å¤‡: {device}")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        print("4. æµ‹è¯•å‰å‘ä¼ æ’­...")
        model.eval()
        with torch.no_grad():
            for batch in train_loader:
                X_batch, y_batch = batch
                X_batch, y_batch = X_batch.to(device), y_batch.to(device)
                
                output = model(X_batch)
                
                print(f"   è¾“å…¥å½¢çŠ¶: {X_batch.shape}")
                print(f"   è¾“å‡ºå½¢çŠ¶: {output.shape}")
                print(f"   ç›®æ ‡å½¢çŠ¶: {y_batch.shape}")
                print(f"   è¾“å‡ºèŒƒå›´: [{output.min().item():.4f}, {output.max().item():.4f}]")
                break
        
        # æµ‹è¯•è®­ç»ƒæ­¥éª¤
        print("5. æµ‹è¯•è®­ç»ƒæ­¥éª¤...")
        model.train()
        optimizer = torch.optim.AdamW(model.parameters(), lr=params.learning_rate)
        criterion = torch.nn.MSELoss()
        
        for batch in train_loader:
            X_batch, y_batch = batch
            X_batch, y_batch = X_batch.to(device), y_batch.to(device)
            
            optimizer.zero_grad()
            output = model(X_batch)
            loss = criterion(output, y_batch)
            loss.backward()
            optimizer.step()
            
            print(f"   æŸå¤±å€¼: {loss.item():.4f}")
            break
        
        print("âœ“ Graph Transformeræ¨¡å‹æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âœ— Graph Transformeræ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_graph_transformer()
    
    print("\n" + "=" * 60)
    if success:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
    print("=" * 60)
