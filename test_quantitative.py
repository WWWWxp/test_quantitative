#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•é‡åŒ–æ¨¡å‹å’Œæ•°æ®é›†çš„è„šæœ¬
"""
import os
import sys
import torch
import numpy as np
from tqdm import tqdm

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.append('.')

from params import params
from dataset import load_data, split_time_series_data, StockDataset
from model import create_model
from torch.utils.data import DataLoader

def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    print("=== æµ‹è¯•æ•°æ®åŠ è½½ ===")
    try:
        # å¯ç”¨æµ‹è¯•æ¨¡å¼
        params.test_mode = True
        
        X, y, time_stamps = load_data()
        print(f"âœ“ æ•°æ®åŠ è½½æˆåŠŸ")
        print(f"  - X shape: {X.shape}")
        print(f"  - y shape: {y.shape}")
        print(f"  - æ—¶é—´æˆ³æ•°é‡: {len(time_stamps)}")
        print(f"  - æ—¶é—´èŒƒå›´: {time_stamps[0]} è‡³ {time_stamps[-1]}")
        
        # æµ‹è¯•æ•°æ®åˆ†å‰²
        (X_train, X_val, X_test), (y_train, y_val, y_test), (ts_train, ts_val, ts_test) = split_time_series_data(X, y, time_stamps)
        print(f"âœ“ æ•°æ®åˆ†å‰²æˆåŠŸ")
        print(f"  - è®­ç»ƒé›†: {X_train.shape}, {y_train.shape}")
        print(f"  - éªŒè¯é›†: {X_val.shape}, {y_val.shape}")
        print(f"  - æµ‹è¯•é›†: {X_test.shape}, {y_test.shape}")
        
        return True
    except Exception as e:
        print(f"âœ— æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return False

def test_dataset():
    """æµ‹è¯•æ•°æ®é›†"""
    print("\n=== æµ‹è¯•æ•°æ®é›† ===")
    try:
        # å¯ç”¨æµ‹è¯•æ¨¡å¼
        params.test_mode = True
        
        X, y, time_stamps = load_data()
        (X_train, X_val, X_test), (y_train, y_val, y_test), (ts_train, ts_val, ts_test) = split_time_series_data(X, y, time_stamps)
        
        # åˆ›å»ºæ•°æ®é›†
        train_dataset = StockDataset(X_train[:100], y_train[:100])  # åªå–å‰100ä¸ªæ ·æœ¬æµ‹è¯•
        print(f"âœ“ æ•°æ®é›†åˆ›å»ºæˆåŠŸ")
        print(f"  - æ•°æ®é›†å¤§å°: {len(train_dataset)}")
        
        # æµ‹è¯•æ•°æ®è·å–
        X_sample, y_sample = train_dataset[0]
        print(f"âœ“ æ•°æ®è·å–æˆåŠŸ")
        print(f"  - X sample shape: {X_sample.shape}")
        print(f"  - y sample shape: {y_sample.shape}")
        print(f"  - X sample dtype: {X_sample.dtype}")
        print(f"  - y sample dtype: {y_sample.dtype}")
        
        # æµ‹è¯•æ•°æ®åŠ è½½å™¨
        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
        print(f"âœ“ æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        print(f"  - æ‰¹æ¬¡æ•°é‡: {len(train_loader)}")
        
        # æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡
        for X_batch, y_batch in train_loader:
            print(f"âœ“ æ‰¹æ¬¡æ•°æ®è·å–æˆåŠŸ")
            print(f"  - X batch shape: {X_batch.shape}")
            print(f"  - y batch shape: {y_batch.shape}")
            break
        
        return True
    except Exception as e:
        print(f"âœ— æ•°æ®é›†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_model():
    """æµ‹è¯•æ¨¡å‹"""
    print("\n=== æµ‹è¯•æ¨¡å‹ ===")
    try:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ä½¿ç”¨è®¾å¤‡: {device}")
        
        # åˆ›å»ºæ¨¡å‹
        model = create_model(params).to(device)
        print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # ç»Ÿè®¡å‚æ•°
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        print(f"  - æ€»å‚æ•°é‡: {total_params:,} ({total_params/1e6:.2f}M)")
        print(f"  - å¯è®­ç»ƒå‚æ•°é‡: {trainable_params:,} ({trainable_params/1e6:.2f}M)")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        dummy_input = torch.randn(2, 15, 12, 8).to(device)  # [B, T, N, F]
        print(f"âœ“ æ¨¡å‹å‰å‘ä¼ æ’­æµ‹è¯•")
        print(f"  - è¾“å…¥å½¢çŠ¶: {dummy_input.shape}")
        
        with torch.no_grad():
            output = model(dummy_input)
            print(f"  - è¾“å‡ºå½¢çŠ¶: {output.shape}")
            print(f"  - è¾“å‡ºç±»å‹: {output.dtype}")
            print(f"  - è¾“å‡ºèŒƒå›´: [{output.min().item():.4f}, {output.max().item():.4f}]")
        
        return True
    except Exception as e:
        print(f"âœ— æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_training_step():
    """æµ‹è¯•è®­ç»ƒæ­¥éª¤"""
    print("\n=== æµ‹è¯•è®­ç»ƒæ­¥éª¤ ===")
    try:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # åˆ›å»ºæ¨¡å‹å’Œä¼˜åŒ–å™¨
        model = create_model(params).to(device)
        optimizer = torch.optim.AdamW(model.parameters(), lr=params.learning_rate, weight_decay=1e-4)
        criterion = torch.nn.SmoothL1Loss(beta=0.5)
        
        # åˆ›å»ºå°æ•°æ®é›†
        params.test_mode = True
        X, y, time_stamps = load_data()
        (X_train, X_val, X_test), (y_train, y_val, y_test), (ts_train, ts_val, ts_test) = split_time_series_data(X, y, time_stamps)
        train_dataset = StockDataset(X_train[:100], y_train[:100])
        train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
        
        print(f"âœ“ è®­ç»ƒç»„ä»¶åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•ä¸€ä¸ªè®­ç»ƒæ­¥éª¤
        model.train()
        for X_batch, y_batch in train_loader:
            X_batch, y_batch = X_batch.to(device), y_batch.to(device)
            
            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            output = model(X_batch)
            loss = criterion(output, y_batch)
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            print(f"âœ“ è®­ç»ƒæ­¥éª¤æˆåŠŸ")
            print(f"  - æŸå¤±å€¼: {loss.item():.4f}")
            print(f"  - è¾“å‡ºå½¢çŠ¶: {output.shape}")
            print(f"  - ç›®æ ‡å½¢çŠ¶: {y_batch.shape}")
            break
        
        return True
    except Exception as e:
        print(f"âœ— è®­ç»ƒæ­¥éª¤æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_learner():
    """æµ‹è¯•Learner"""
    print("\n=== æµ‹è¯•Learner ===")
    try:
        from learner import Learner
        
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # åˆ›å»ºæ¨¡å‹å’Œä¼˜åŒ–å™¨
        model = create_model(params).to(device)
        optimizer = torch.optim.AdamW(model.parameters(), lr=params.learning_rate, weight_decay=1e-4)
        
        # åˆ›å»ºå°æ•°æ®é›†
        params.test_mode = True
        X, y, time_stamps = load_data()
        (X_train, X_val, X_test), (y_train, y_val, y_test), (ts_train, ts_val, ts_test) = split_time_series_data(X, y, time_stamps)
        train_dataset = StockDataset(X_train[:100], y_train[:100])
        val_dataset = StockDataset(X_val[:50], y_val[:50])
        
        train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)
        val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)
        
        # åˆ›å»ºLearner
        learner = Learner('./test_output', model, train_loader, None, optimizer, params, dev_dataset=val_loader)
        print(f"âœ“ Learneråˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•è®­ç»ƒæ­¥éª¤
        for batch in train_loader:
            loss = learner.train_step(batch, 1)
            print(f"âœ“ Learnerè®­ç»ƒæ­¥éª¤æˆåŠŸ")
            print(f"  - æŸå¤±å€¼: {loss:.4f}")
            break
        
        # æµ‹è¯•è¯„ä¼°
        rmse, r2, pearson = learner.evaluate_dev()
        if rmse is not None:
            print(f"âœ“ Learnerè¯„ä¼°æˆåŠŸ")
            print(f"  - RMSE: {rmse:.4f}")
            print(f"  - R2: {r2:.4f}")
            print(f"  - Pearson: {pearson:.4f}")
        
        return True
    except Exception as e:
        print(f"âœ— Learneræµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æµ‹è¯•é‡åŒ–æ¨¡å‹å’Œæ•°æ®é›†...")
    print("=" * 50)
    
    tests = [
        test_data_loading,
        test_dataset,
        test_model,
        test_training_step,
        test_learner
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        try:
            if test():
                passed += 1
        except Exception as e:
            print(f"æµ‹è¯• {test.__name__} å‡ºç°å¼‚å¸¸: {e}")
    
    print("\n" + "=" * 50)
    print(f"æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå¯ä»¥æ­£å¸¸ä½¿ç”¨ã€‚")
        return True
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œæ•°æ®ã€‚")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
